{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Introduction\n",
    "In this note we go through the concept of Kalman filter, the notebook is heavily inspired by lessons from [Udacity course](https://www.udacity.com/drive).\n",
    "\n",
    "The notebook is organized as following\n",
    "\n",
    "* Re-call on Gaussian distribution\n",
    "* Kalman filter in 1D space\n",
    "* \n",
    "\n",
    "# II. Gaussian distribution\n",
    "The Gaussian distribution has following form for 1D variable\n",
    "\n",
    "$$\n",
    "\\mathcal{N}(x\\ |\\ \\mu,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left\\{-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right\\}\n",
    "$$\n",
    "\n",
    "where $\\mu$ is the mean and $\\sigma^2$ is the variance. \n",
    "\n",
    "For $D-$dimension, it takes the form\n",
    "\n",
    "$$\n",
    "\\mathcal{N}(x\\ |\\ \\mu,\\Sigma^2) = \\frac{1}{(2\\pi)^{D/2}|\\Sigma|^{1/2}}\\exp\\left\\{-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu)\\right\\}\n",
    "$$\n",
    "\n",
    "### Conditional/Marginal Gaussian\n",
    "Consider $\\mathcal{N}(x\\ |\\ \\mu,\\Sigma)$ with $\\Lambda=\\Sigma^{-1}$ and\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "&x =\\left(\\begin{array}{c}x_a\\\\ x_b\\end{array}\\right),\\ &\\mu=\\left(\\begin{array}{c}\\mu_a\\\\ \\mu_b\\end{array}\\right)\\\\\n",
    "&\\Sigma = \\left(\\begin{array}{cc}\\Sigma_{aa} & \\Sigma_{ab}\\\\ \\Sigma_{ba} & \\Sigma_{bb}\\end{array}\\right),\\ \n",
    "&\\Lambda= \\left(\\begin{array}{cc}\\Lambda_{aa} & \\Lambda_{ab}\\\\ \\Lambda_{ba} & \\Lambda_{bb}\\end{array}\\right)\\end{split}\n",
    "$$\n",
    "\n",
    "Then we have\n",
    "* Conditional distribution\n",
    "$$\n",
    "\\begin{split}\n",
    "p(x_a|x_b) &= \\mathcal{N}\\left(x\\ |\\ \\mu_{a|b},\\Lambda_{aa}^{-1}\\right)\\\\\n",
    "\\mu_{a|b} &= \\mu_a-\\Lambda_{aa}^{-1}\\Lambda_{ab}(x_b - \\mu_b)\n",
    "\\end{split}\n",
    "$$\n",
    "* Marginal distribution\n",
    "$$\n",
    "p(x_a) = \\mathcal{N}\\left(x_a\\ |\\ \\mu_a, \\Sigma_{aa}\\right)\n",
    "$$\n",
    "\n",
    "### Bayes' theorem for Gaussian variables\n",
    "Given the prior and conditional distribution (linear Gaussian model)\n",
    "$$\n",
    "\\begin{split}\n",
    "p(x) &= \\mathcal{N}\\left(x\\ |\\ \\mu,\\Lambda^{-1}\\right)\\\\\n",
    "p(y\\ |\\ x) &= \\mathcal{N}\\left(y\\ |\\ Ax + b, L^{-1}\\right)\n",
    "\\end{split}\n",
    "$$\n",
    "And we want to find the marginal distribution $p(y)$ and the conditional distribution (also called posteriori) distribution $p(x\\ |\\ y)$.\n",
    "\n",
    "We have (proof can be found in chapter 2 in Bishop's book)\n",
    "$$\n",
    "\\begin{split}\n",
    "p(y)   &= \\mathcal{N}\\left(y\\ |\\ A\\mu+b,L^{-1} + A\\Lambda^{-1}A^T\\right)\\\\\n",
    "p(x|y) &= \\mathcal{N}\\left(x\\ |\\ \\Sigma\\left\\{A^TL(y-b) + \\Lambda\\mu\\right\\}, \\Sigma\\right)\n",
    "\\end{split}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\Sigma=\\left(\\Lambda + A^TLA\\right)^{-1}\n",
    "$$\n",
    "\n",
    "# III. 1D-Kalman filter\n",
    "Now let's look"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
