{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Introduction\n",
    "In this note we go through the concept of Kalman filter, the notebook is heavily inspired by lessons from [Udacity course](https://www.udacity.com/drive).\n",
    "\n",
    "The notebook is organized as following\n",
    "\n",
    "* Re-call on Gaussian distribution\n",
    "* Kalman filter in 1D space\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Gaussian distribution\n",
    "The Gaussian distribution has following form for 1D variable\n",
    "\n",
    "$$\n",
    "\\mathcal{N}(x\\ |\\ \\mu,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left\\{-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right\\}\n",
    "$$\n",
    "\n",
    "where $\\mu$ is the mean and $\\sigma^2$ is the variance. \n",
    "\n",
    "For $D-$dimension, it takes the form\n",
    "\n",
    "$$\n",
    "\\mathcal{N}(x\\ |\\ \\mu,\\Sigma^2) = \\frac{1}{(2\\pi)^{D/2}|\\Sigma|^{1/2}}\\exp\\left\\{-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu)\\right\\}\n",
    "$$\n",
    "\n",
    "### Conditional/Marginal Gaussian\n",
    "Consider $\\mathcal{N}(x\\ |\\ \\mu,\\Sigma)$ with $\\Lambda=\\Sigma^{-1}$ and\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "&x =\\left(\\begin{array}{c}x_a\\\\ x_b\\end{array}\\right),\\ &\\mu=\\left(\\begin{array}{c}\\mu_a\\\\ \\mu_b\\end{array}\\right)\\\\\n",
    "&\\Sigma = \\left(\\begin{array}{cc}\\Sigma_{aa} & \\Sigma_{ab}\\\\ \\Sigma_{ba} & \\Sigma_{bb}\\end{array}\\right),\\ \n",
    "&\\Lambda= \\left(\\begin{array}{cc}\\Lambda_{aa} & \\Lambda_{ab}\\\\ \\Lambda_{ba} & \\Lambda_{bb}\\end{array}\\right)\\end{split}\n",
    "$$\n",
    "\n",
    "Then we have\n",
    "* Conditional distribution\n",
    "$$\n",
    "\\begin{split}\n",
    "p(x_a|x_b) &= \\mathcal{N}\\left(x\\ |\\ \\mu_{a|b},\\Lambda_{aa}^{-1}\\right)\\\\\n",
    "\\mu_{a|b} &= \\mu_a-\\Lambda_{aa}^{-1}\\Lambda_{ab}(x_b - \\mu_b)\n",
    "\\end{split}\n",
    "$$\n",
    "* Marginal distribution\n",
    "$$\n",
    "p(x_a) = \\mathcal{N}\\left(x_a\\ |\\ \\mu_a, \\Sigma_{aa}\\right)\n",
    "$$\n",
    "\n",
    "### Bayes' theorem for Gaussian variables\n",
    "We recall Bayes' theorem\n",
    "$$\n",
    "\\begin{split}\n",
    "\\mathbb{P}(X,Y) = \\mathbb{P}(X\\ |\\ Y)\\mathbb{P}(Y)=\\mathbb{P}(Y\\ |\\ X)\\mathbb{P}(X)\\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Given the prior and conditional distribution (linear Gaussian model)\n",
    "$$\n",
    "\\begin{split}\n",
    "p(x) &= \\mathcal{N}\\left(x\\ |\\ \\mu,\\Lambda^{-1}\\right)\\\\\n",
    "p(y\\ |\\ x) &= \\mathcal{N}\\left(y\\ |\\ Ax + b, L^{-1}\\right)\n",
    "\\end{split}\n",
    "$$\n",
    "One can apply Bayes' theorem to find the marginal distribution $p(y)$ and the conditional distribution (also called posteriori) distribution $p(x\\ |\\ y)$.\n",
    "\n",
    "We have (proof can be found in chapter 2 in Bishop's book)\n",
    "$$\n",
    "\\begin{split}\n",
    "p(y)   &= \\mathcal{N}\\left(y\\ |\\ A\\mu+b,L^{-1} + A\\Lambda^{-1}A^T\\right)\\\\\n",
    "p(x|y) &= \\mathcal{N}\\left(x\\ |\\ \\Sigma\\left\\{A^TL(y-b) + \\Lambda\\mu\\right\\}, \\Sigma\\right)\n",
    "\\end{split}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\Sigma=\\left(\\Lambda + A^TLA\\right)^{-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Kalman filter\n",
    "The [Kalman filter](https://en.wikipedia.org/wiki/Kalman_filter) is an algorithm to estimate current state by iterating on two main cycles: mesurement update/motion update (also called update step/prediction step)\n",
    "\n",
    "* **Measurement update**: given a measurement, we update the distribution of the current state\n",
    "* **Motion update**: given a physical update (e.g move forward 10m), we predict the distribution of the next state\n",
    "\n",
    "Let's go through some example (taken for Udacity course), consider a robot and a line of 5 squares (each is either green or red) as the following image\n",
    "\n",
    "![robot_loc](assets/kalman_locs.png)\n",
    "\n",
    "The robot can be in any square with uniform probability 0.2, denote $X$ as our robot's the location\n",
    "\n",
    "$$\n",
    "P(X=i) = 0.2\n",
    "$$\n",
    "\n",
    "We know that our robot can sense its location's color, denote $Y$ as the sensed color, we have $Y\\in\\left\\{\\text{red, green}\\right\\}$\n",
    "\n",
    "### Measurement update\n",
    "Now, if the robot sensed the color red $Y=\\text{red}$, what is the distribution of robot's location i.e \n",
    "$$\n",
    "P(X=i\\ |\\ Y=\\text{red}) = ?\n",
    "$$\n",
    "By applying Bayes' rule, the distribution of robot's location becomes\n",
    "$$\n",
    "P(X=i\\ |\\ Y=\\text{red}) = \\left\\{ \\begin{array}{l}\n",
    "                                    0.5 \\text{ for } i=2,3 \\\\\n",
    "                                    0 \\text{ otherwise}\n",
    "                                  \\end{array}\\right.\n",
    "$$\n",
    "So with an additional info (color sensing), we know more precise about our robot's location. This is the **Measurement update** step.\n",
    "\n",
    "### Motion update\n",
    "Now, let's our robot to move one step to the right, given previous step's distribution we know that\n",
    "$$\n",
    "P(X=i) = \\left\\{ \\begin{array}{l}\n",
    "                  0.5 \\text{ for } i=3,4 \\\\\n",
    "                  0 \\text{ otherwise}\n",
    "                  \\end{array}\\right.\n",
    "$$\n",
    "If we sense the color **red** again, applying another **Measurement update** then we know for sure that our robot's current location must be 3.\n",
    "\n",
    "So we go through an example where robot's location is discrete and measurement/motion update is perfect (no noise). The Kalman filter is much more powerful and it can handle \n",
    "\n",
    "* state is continuous (1D or multi-dimensional)\n",
    "* measurement can have Gaussian noise\n",
    "* motion update can have Gaussian noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's dive into 1D-case\n",
    "### 1D Kalman filter\n",
    "Now we consider a car that drives on a straight line with constant speed $v$ and we denote \n",
    "\n",
    "* $x_t$ is the real position of the car at time $t$ (which we don't know exactly) and \n",
    "* $y_t$ is position obtained via GPS (which might have small errror/noise)\n",
    "\n",
    "We also assume the initial location $x_0\\sim\\mathcal{N}(\\mu_0, \\sigma_0^2)$, and all noise/error is of Gaussian distribution i.e\n",
    "$$\n",
    "\\begin{split}\n",
    "y_t &= x_t + \\epsilon,&\\quad \\epsilon\\sim\\mathcal{N}(0, \\theta^2)\\\\\n",
    "x_t &= x_{t-1} + v + \\xi,&\\quad \\xi \\sim\\mathcal{N}(0, \\sigma^2)\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "The goal is to estimate $x_t$ given observed $y_t$. Since the noise/error are random, we can only estimate the distribution of $x_t$ i.e\n",
    "$$\n",
    "\\mathbb{P}(x_t\\ |\\ y_t)\n",
    "$$\n",
    "This is done in two steps, suppose we have from previous step $x_{t-1}\\sim\\mathcal{N}(\\mu_{t-1}, \\sigma_{t-1}^2)$\n",
    "* Motion update\n",
    "$$\n",
    "x_t = x_{t-1} + v + \\xi \\sim \\mathcal{N}(x_t \\ |\\ \\mu_{t-1} + v, \\sigma_{t-1}^2 + \\sigma^2)\n",
    "$$\n",
    "* Measurement update, we know that\n",
    "$$\n",
    "p(y_t\\ |\\ x_t) \\sim \\mathcal{N}(y_t\\ |\\ x_t, \\theta^2)\n",
    "$$\n",
    "\n",
    "So we have\n",
    "$$\n",
    "\\begin{split}\n",
    "p(x_t) & \\sim \\mathcal{N}(x_t \\ |\\ \\mu_{t-1} + v, \\sigma_{t-1}^2 + \\sigma^2)\\\\\n",
    "p(y_t\\ |\\ x_t) & \\sim \\mathcal{N}(y_t \\ |\\ x_t, \\theta^2)\n",
    "\\end{split}\n",
    "$$\n",
    "Applying Bayes' theorem for Gaussian, we obtain\n",
    "$$\n",
    "\\begin{split}\n",
    "p(y_t) &\\sim \\\\\n",
    "p(x_t\\ |\\ y_t) &\\sim \n",
    "\\end{split}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
